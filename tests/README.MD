maplet Testing Framework
========================

What is the maplet Testing Framework?
-------------------------------------

The maplet package was designed to create pipelines utilizing a
container object and pipe operators to seamlessly chain together
functions. While this offers several advantages, such as high
readability and giving users the ability to record and trace all
intermediate steps and results, it makes it difficult to implement and
maintain traditional testing methods, such as unit testing. This is
because many maplet functions cannot be meaningfully evaluated in
isolation, making them incompatible with unit testing's approach of one
test for one function.

Therefore, we've developed an alternative method of evaluating the
functionality of maplet functions -- called the maplet Testing Framework
-- to **ensure that maplet pipelines continue to work as expected as the
package is developed**. The maplet Testing Framework provides methods for
assessing the 'equality' of two maplet pipeline objects by comparing the
components of each object that are expected to be identical. It also
allows for the results of functions to be evaluated sequentially,
ensuring that each function produces a meaningful result.

The following 3 sections describe the process of preparing a pipeline
for testing, setting up the testing framework, and running the testing
framework. These are presented in the order they must be carried out.
The fourth section describes how to interpret the results of the
pipeline. The last section is an overview of how the testing framework
works internally; it is intended for developers and can be ignored by users.

Preparing a Pipeline for Testing
--------------------------------

Before setting up the testing framework, the user must ensure the script
of the pipeline of interest is compatible with the testing framework.
Specifically, the script must satisfy the following requirements:

1.  **The pipeline should end with the following command**:
```
    mt_clean_remove_results(remove="plots")
```

This command removes all plots from the pipeline object. The maplet
testing framework currently excludes plots as there is no convenient
method for automatically comparing them. Removing them significantly
reduces the size of the pipeline object generated, which in turn
allows the testing framework to run faster.

2.  **All arguments must be passed as atomic values to mt\_ functions -- do not
    pass variable names.**

This is necessary to ensure the testing-formatted script can be run by
the maplet testing functions. For example, the following will not run:
```
alpha = 0.5
mt_pre_filter_missingness(filter = alpha)
```
instead, write:
```
mt_pre_filter_missingness(filter = 0.5)
```

Setting Up the Testing Framework
--------------------------------

The maplet testing framework is intended to compare the result objects
of a pipeline at the time of testing to reference result objects
generated at an earlier point in which the pipeline was known to work as
desired. It also requires a testing-formatted script that can be run
automatically by the framework. Both the reference objects and the
testing-formatted script are generated by following these steps:

1.  Create a local folder -- the project testing folder -- for storing
    the pipeline-specific testing materials.

2.  Place a copy of the script for the pipeline of interest in the
    project testing folder.

3.  Open the script **convert_pipeline_to_test.R**.

4.  Set the values for the following variable:

    -  **file** -- name of the pipeline file; must be located in the
    project testing directory

5.  Source the script.

After running **convert_pipeline_to_test.R**, you should find the
following in the project testing folder:

-   A test_steps_file to be used by the script **run_maplet_test.R**

-   A save_steps_file that will have been sourced by the conversion
    script to create the reference objects

-   A directory named **REFERENCE_OBJECTS/** that will contain every
    intermediate step of the pipeline

**NOTE:** The conversion script may take several minutes to run
depending on the number of steps in the pipeline and the size of the
data used by the pipeline.

Running the Testing Framework
-----------------------------

Once a testing framework has been set up, the user can run it at a later
point in time (e.g. after changes to one or more of the functions
utilized by the pipeline) to ensure that the pipeline continues to work
as expected. To run the maplet testing framework, follow the
instructions below:

1.  Open the script **run_maplet_test.R**.

2.  Set values for the following variable:

    -  **file** -- name of the pipeline file; must be located in the
    project testing directory

3.  Source the script.

**IMPORTANT:** The pipelines must be IDENTICAL. They cannot be
meaningfully compared otherwise, and the script will crash.

Interpreting Results
--------------------

The **run_maplet_test.R** script performs two types of assessments:
**global** and **stepwise**. The **global** assessment evaluates only
the final result of a pipeline and will always be performed. The
**stepwise** assessment is only performed if one or more of the tests
fail in the global assessment. It allows the user to identify where a
change has occurred in the pipeline by incrementally running each
intermediate step and comparing the results. The **global** assessment
produces the result data frame **global_results_df**. This data frame contains
two columns:

-   **test** -- name of the test that was run

-   **result** -- result of the test: 'Pass' or 'Fail'

Each row in the data frame corresponds to a comparison test performed on
the two pipeline objects. The following is a list of the potential tests
that could be performed on the two objects:

-   **assay\*** -- checks objects have identical assay data frames

-   **rowData\*** -- checks objects have identical rowData data frames

-   **colData\*** -- checks objects have identical colData data frames

-   **stats_len** -- checks objects have the same number of statistical
    result tables

-   **stats\_\#** - for each statistical result, checks that the
    statistical result tables are identical between the two objects

-   **pathways_len** -- checks objects have the same number of pathway
    annotation data frames

-   **pathways\_\#** - for each pathway annotation data frame, checks
    data frames are identical between the two objects

\* These tests are always performed. Other tests may or may not be
performed depending on the function calls detected in the pipeline.

The **stepwise** assessment is run automatically by the script if and
only if one or more tests fail in the global assessment. It produces the
data frame **stepwise_results_df** which contains four columns:

-   **step** -- a number representing the step in the pipeline

-   **fun** -- the name of the function called at this step in the
    pipeline

-   **test** -- name of the test that was run

-   **result** -- the result of the test: 'Pass' or 'Fail'

The **stepwise** assessment is useful in helping users identify where in
the pipeline issues have occurred. For example, say the global
assessment returns 'Fail' for the 'assay' comparison test. It's clear
that the assays are not the same between the two data frames, but it is
unclear where in the pipeline the assays begin to differentiate. The
user can search the **stepwise_results_df** to find the first instance where
**test** 'assay' returns **result** 'Fail'. This will also provide them
with the name of the function where the issue occurred and what step in
the pipeline at which it occurred.

How the Testing Framework Works Internally
--------------------------------------------

The following is a description of the inner workings of the testing
framework. It is intended for developers and can be safely ignored by
users.

The **run_maplet_test.R** script utilizes two maplet testing functions
(denoted with prefix **mtt\_**). These are:

-   **mtt_equal** -- comparison function for assessing the 'equality' of
    two maplet pipeline container objects with identical function calls

-   **mtt_stepwise_compare** -- comparison function for each
    intermediate maplet container object produced by a maplet pipeline

When **run_maplet_test.R** is run, the two full-pipeline objects are
first compared using the function **mtt_equal**. This function takes as
input two maplet pipeline objects. It performs the **global** assessment
of the pipeline objects described above. Internally, it finds and
compares all corresponding data frames using the function identical().
Results are assembled into the **global_results_df** data frame, described above,
and returned to the user.

If all of the tests return 'Pass' for the **global** assessment, the
**stepwise** assessment will not be run. Otherwise, the script will
automatically run the function **mtt_compare_stepwise**. This function
takes as input the formatted testing script returned by
**convert_pipeline_to_test.R**, the path to the directory containing
reference objects for each individual step, and the prefix used to name
the reference objects. **mtt_compare_stepwise** reads in the
testing-formatted script runs each step of the pipeline individually,
comparing each intermediate result generated to the corresponding
reference result from the reference objects directory. It calls
**mtt_equal** to perform a comparison between the objects generated at
each step. Once every intermediate result has been evaluated, the
results are assembled into the **stepwise_results_df** data frame, described
above, and return to the user.
